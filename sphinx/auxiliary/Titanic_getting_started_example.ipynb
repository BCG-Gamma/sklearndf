{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# this cell's metadata contains\n",
    "# \"nbsphinx\": \"hidden\" so it is hidden by nbsphinx\n",
    "\n",
    "def _set_paths() -> None:\n",
    "    # set the correct path when launched from within PyCharm\n",
    "\n",
    "    module_paths = [\"pytools\", \"facet\", \"sklearndf\"]\n",
    "\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    if 'cwd' not in globals():\n",
    "        # noinspection PyGlobalUndefined\n",
    "        global cwd\n",
    "        cwd = os.path.join(os.getcwd(), os.pardir, os.pardir, os.pardir)\n",
    "        os.chdir(cwd)   \n",
    "    print(f\"working dir is '{os.getcwd()}'\")\n",
    "    for module_path in module_paths:\n",
    "        if module_path not in sys.path:\n",
    "            sys.path.insert(0, os.path.abspath(f\"{cwd}/{os.pardir}/{module_path}/src\"))\n",
    "        print(f\"added `{sys.path[0]}` to python paths\")\n",
    "        \n",
    "def _ignore_warnings():\n",
    "    # ignore irrelevant warnings that would affect the output of this tutorial notebook\n",
    "    \n",
    "    # ignore a useless LGBM warning\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, message=r\".*Xcode_8\\.3\\.3\")\n",
    "\n",
    "_set_paths()\n",
    "_ignore_warnings()\n",
    "\n",
    "del _set_paths, _ignore_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "# this cell's metadata contains\n",
    "# \"nbsphinx\": \"hidden\" so it is hidden by nbsphinx\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def _configure_matplotlib():\n",
    "    # set global options for matplotlib\n",
    "    \n",
    "    import matplotlib\n",
    "    \n",
    "    matplotlib.rcParams['figure.figsize'] = (16.0, 8.0)\n",
    "    matplotlib.rcParams['figure.dpi'] = 72\n",
    "\n",
    "_configure_matplotlib()\n",
    "\n",
    "del _configure_matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a DataFrame friendly scikit-learn pre-processing pipeline\n",
    "\n",
    "The titanic data set includes categorical features such as class and sex, and also has missing values for numeric features (i.e., age) and categorical features (i.e., embarked). The aim is to predict whether or not a passenger survived. A standard sklearn example for this dataset can be found [here](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py)\n",
    "\n",
    "We will build a preprocessing pipeline which:\n",
    "\n",
    "- for categorical variables fills missing values with the string Ã¢â‚¬ËœUnknownÃ¢â‚¬â„¢ and then one-hot encodes\n",
    "\n",
    "- for numerical values fills missing values using median values\n",
    "\n",
    "The strength of `sklearndf` is to maintain the scikit-learn conventions and expressivity, while also preserving dataframes, and hence feature names. We can see this after using fit_transform on our preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Relevant sklearndf imports\n",
    "from sklearndf.transformation import (\n",
    "    ColumnTransformerDF,\n",
    "    OneHotEncoderDF,\n",
    "    SimpleImputerDF,\n",
    ")\n",
    "from sklearndf.pipeline import (\n",
    "    PipelineDF,\n",
    "    ClassifierPipelineDF\n",
    ")\n",
    "from sklearndf.classification import RandomForestClassifierDF\n",
    "\n",
    "# Load titanic data\n",
    "titanic_X, titanic_y = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "\n",
    "# Select features\n",
    "numerical_features = ['age', 'fare']\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "\n",
    "# Create a pre-processing pipeline\n",
    "preprocessing_numeric_df = SimpleImputerDF(strategy=\"median\")\n",
    "\n",
    "preprocessing_categorical_df = PipelineDF(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputerDF(strategy='constant', fill_value='Unknown')),\n",
    "        ('one-hot', OneHotEncoderDF(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessing_df = ColumnTransformerDF(\n",
    "    transformers=[\n",
    "        ('categorical', preprocessing_categorical_df, categorical_features),\n",
    "        ('numeric', preprocessing_numeric_df, numerical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Run pre-processing\n",
    "transformed_df = preprocessing_df.fit_transform(X=titanic_X, y=titanic_y)\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing features from post-transform to original\n",
    "\n",
    "The `sklearndf` pipeline has a features_original attribute which returns a series mapping the output columns (the seriesÃ¢â‚¬â„¢ index) to the input columns (the seriesÃ¢â‚¬â„¢ values). We can therefore easily select all output features generated from a given input feature, such as in this case for embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embarked_type_derivatives = preprocessing_df.features_original == \"embarked\"\n",
    "transformed_df.loc[:, embarked_type_derivatives].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the pipeline with a classifier\n",
    "\n",
    "Scikit-learn regressors and classifiers have a `sklearndf` sibling obtained by appending DF to the class name; the API remains the same. The result of any predict and decision function will be returned as a pandas series (single output) or data frame (class probabilities or multi-output).\n",
    "\n",
    "We can combine the preprocessing pipeline above with a classifier to create a full predictive pipeline. sklearndf provides two useful, specialised pipeline objects for this, `RegressorPipelineDF` and `ClassifierPipelineDF`. Both implement a special two-step pipeline with one pre-processing step and one prediction step, while staying compatible with the general sklearn pipeline idiom.\n",
    "\n",
    "Using `ClassifierPipelineDF` we can combine the preprocessing pipeline with `RandomForestClassifierDF()` to fit a model to a selected training set and then score and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facet.simulation import UnivariateUpliftSimulator\n",
    "from facet.simulation.partition import ContinuousRangePartitioner\n",
    "from facet.simulation.viz import SimulationDrawer\n",
    "\n",
    "SIM_FEAT = \"LSTAT\"\n",
    "simulator = UnivariateUpliftSimulator(crossfit = ranker.best_model_crossfit, n_jobs=3)\n",
    "\n",
    "# Split the simulation range into equal sized partitions\n",
    "partitioner = ContinuousRangePartitioner()\n",
    "\n",
    "simulation = simulator.simulate_feature(name=SIM_FEAT, partitioner = partitioner)\n",
    "\n",
    "SimulationDrawer().draw(\n",
    "    data=simulation, title=SIM_FEAT\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}